resources:
  - repo: self

trigger:
  - main

variables:
  databricks-host: 'https://adb-4188668828067310.10.azuredatabricks.net'
  notebook-folder: '/Users/tushar.pathak@tigeranalytics.com/'
  cluster-id: '0708-064558-lglz5exu'
  notebook-name: 'Deepchecks_Model_Testing_v1'
  html-report-workspace-path-data-integrity: '/Workspace/Users/tushar.pathak@tigeranalytics.com/Reports/Data_Integrity_Report.html'
  local-html-report-path-1: '$(Build.ArtifactStagingDirectory)/Data_Integrity_Report.html'
  html-report-workspace-path-train: '/Workspace/Users/tushar.pathak@tigeranalytics.com/Reports/Test_Train_Validation_Report.html'
  local-html-report-path-2: '$(Build.ArtifactStagingDirectory)/Test_Train_Validation_Report.html'

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.7'
    addToPath: true
    architecture: 'x64'
  displayName: 'Use Python 3.x'

- script: |
    pip install databricks-cli jq
  displayName: 'Install databricks-cli and jq'

- script: |
    # Configure Databricks CLI
    databricks jobs configure --version=2.1

    # Create a new job and capture the Job ID
    JOB_ID=$(databricks jobs create --json '{
     "name": "Testrun",
     "existing_cluster_id": "$(cluster-id)",
     "timeout_seconds": 3600,
     "max_retries": 1,
     "notebook_task": {
       "notebook_path": "$(notebook-folder)$(notebook-name)",
       "base_parameters": {}
     }
    }' | jq -r '.job_id')

    echo "Job ID: $JOB_ID"

    # Check if JOB_ID is empty
    if [ -z "$JOB_ID" ]; then
      echo "Error: Job ID is empty. Exiting."
      exit 1
    fi

    # Run the job and capture the Run ID
    RUN_ID=$(databricks jobs run-now --job-id "$JOB_ID" | jq -r '.run_id')

    echo "Run ID: $RUN_ID"

    # Check if RUN_ID is empty
    if [ -z "$RUN_ID" ]; then
      echo "Error: Run ID is empty. Exiting."
      exit 1
    fi

    # Poll for job status
    job_status="PENDING"
    while [ "$job_status" = "RUNNING" ] || [ "$job_status" = "PENDING" ]
    do
     sleep 2
     job_status=$(databricks runs get --run-id "$RUN_ID" | jq -r '.state.life_cycle_state')
     echo "Status: $job_status"
    done

    # Get job result
    RESULT=$(databricks runs get-output --run-id "$RUN_ID")

    RESULT_STATE=$(echo "$RESULT" | jq -r '.metadata.state.result_state')
    RESULT_MESSAGE=$(echo "$RESULT" | jq -r '.metadata.state.state_message')

    if [ "$RESULT_STATE" = "FAILED" ]; then
     echo "##vso[task.logissue type=error;]$RESULT_MESSAGE"
     echo "##vso[task.complete result=Failed;done=true;]$RESULT_MESSAGE"
    else
     echo "##vso[task.complete result=Succeeded;done=true;]Job completed successfully"
    fi

    echo "$RESULT" | jq .
  displayName: 'Run Databricks Notebook'

  env:
    DATABRICKS_TOKEN: 'dapi1062f3ecc6b393a6c5934704162792b4-3'
    DATABRICKS_HOST: $(databricks-host)

- script: |
    # Remove existing files if they exist
    if [ -f "$(local-html-report-path-1)" ]; then
        rm "$(local-html-report-path-1)"
    fi
    if [ -f "$(local-html-report-path-2)" ]; then
        rm "$(local-html-report-path-2)"
    fi

    # Download the HTML report from Databricks workspace to local path
    databricks workspace export $(html-report-workspace-path-data-integrity) $(local-html-report-path-1)
    databricks workspace export $(html-report-workspace-path-train) $(local-html-report-path-2)
  displayName: 'Download HTML report'

- task: PublishPipelineArtifact@1
  inputs:
    targetPath: '$(local-html-report-path-1)'
    artifact: 'HTMLReport-DI'
  displayName: 'Publish Data Integrity Report'

- task: PublishPipelineArtifact@1
  inputs:
    targetPath: '$(local-html-report-path-2)'
    artifact: 'HTMLReport-TTV'
  displayName: 'Publish Test Train Report'
