trigger:
  - main

variables:
  databricks_host: 'https://adb-4188668828067310.10.azuredatabricks.net'
  notebook_folder: '/Users/tushar.pathak@tigeranalytics.com/'
  cluster_id: '0708-064558-lglz5exu'
  notebook_name: 'Deepchecks_Model_Testing_v1'

  # Define pipeline variable for Databricks token
  DATABRICKS_TOKEN: $(secret_databricks_token)  # Replace with your secret variable name in Azure DevOps

jobs:
- job: Run_Databricks_Notebook
  displayName: 'Run Databricks Notebook'
  pool:
    vmImage: 'ubuntu-latest'
  
  steps:
  - task: UsePythonVersion@0
    displayName: 'Use Python 3.x'
    inputs:
      versionSpec: '3.x'
      addToPath: true

  - script: |
      pip install databricks-cli
    displayName: 'Install databricks-cli'

  - script: |
      export DATABRICKS_TOKEN='$(DATABRICKS_TOKEN)'
      export DATABRICKS_HOST='$(databricks_host)'

      JOB_ID=$(databricks jobs create --json '{
       "name": "Testrun",
       "existing_cluster_id": "'$cluster_id'",
       "timeout_seconds": 3600,
       "max_retries": 1,
       "notebook_task": {
         "notebook_path": "'$notebook_folder$notebook_name'",
         "base_parameters": {}
       }
      }' | jq -r '.job_id')

      RUN_ID=$(databricks jobs run-now --job-id $JOB_ID | jq -r '.run_id')

      job_status="PENDING"
      while [[ "$job_status" == "RUNNING" || "$job_status" == "PENDING" ]]
      do
       sleep 2
       job_status=$(databricks runs get --run-id $RUN_ID | jq -r '.state.life_cycle_state')
       echo "Status: $job_status"
      done

      RESULT=$(databricks runs get-output --run-id $RUN_ID)

      RESULT_STATE=$(echo $RESULT | jq -r '.metadata.state.result_state')
      RESULT_MESSAGE=$(echo $RESULT | jq -r '.metadata.state.state_message')
      if [[ "$RESULT_STATE" == "FAILED" ]]
      then
       echo "##vso[task.logissue type=error;]$RESULT_MESSAGE"
       echo "##vso[task.complete result=Failed;done=true;]$RESULT_MESSAGE"
       exit 1
      fi

      echo $RESULT | jq .
    displayName: 'Run Databricks Notebook'

  - task: PublishPipelineArtifact@1
    inputs:
      targetPath: '$(Build.ArtifactStagingDirectory)'
      artifact: 'reports'
    condition: always()  # Corrected syntax

  - task: PublishBuildArtifacts@1
    inputs:
      pathToPublish: '$(Build.ArtifactStagingDirectory)'
      artifactName: 'databricks-notebook-artifact'
    condition: always()  # Corrected syntax
