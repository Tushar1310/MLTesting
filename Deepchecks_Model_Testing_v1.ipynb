{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "001bc92e-39cf-4d55-a05f-18f423c74b5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bf4f2a3-5a06-43e4-9638-60e002d67fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import rand, randn, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "298d0faf-d587-4f26-8de0-521391c9fdb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting deepchecks\n  Downloading deepchecks-0.18.1-py3-none-any.whl (7.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 38.4 MB/s eta 0:00:00\nRequirement already satisfied: statsmodels>=0.13.5 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (0.13.5)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (4.11.1)\nRequirement already satisfied: numpy>=1.22.2 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (1.23.5)\nCollecting tqdm>=4.62.3\n  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 11.6 MB/s eta 0:00:00\nRequirement already satisfied: pandas<2.2.0,>=1.1.5 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (1.5.3)\nRequirement already satisfied: scikit-learn<1.4.0,>=0.23.2 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (1.1.1)\nRequirement already satisfied: ipython>=7.15.0 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (8.14.0)\nRequirement already satisfied: ipywidgets<8,>=7.6.5 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (7.7.2)\nCollecting jsonpickle>=2\n  Downloading jsonpickle-3.2.2-py3-none-any.whl (41 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.8/41.8 kB 5.6 MB/s eta 0:00:00\nCollecting PyNomaly>=0.3.3\n  Downloading PyNomaly-0.3.3.tar.gz (8.3 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: matplotlib>=3.3.4 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (3.7.0)\nRequirement already satisfied: scipy<=1.10.1,>=1.4.1 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (1.10.0)\nRequirement already satisfied: typing-extensions>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (4.4.0)\nRequirement already satisfied: requests>=2.22.0 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (2.28.1)\nCollecting plotly>=5.13.1\n  Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 90.4 MB/s eta 0:00:00\nRequirement already satisfied: ipykernel>=5.3.0 in /databricks/python3/lib/python3.10/site-packages (from deepchecks) (6.25.0)\nCollecting category-encoders>=2.3.0\n  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.9/81.9 kB 11.9 MB/s eta 0:00:00\nCollecting jupyter-server>=2.7.2\n  Downloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 383.6/383.6 kB 43.7 MB/s eta 0:00:00\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->deepchecks) (2.3.2.post1)\nRequirement already satisfied: patsy>=0.5.1 in /databricks/python3/lib/python3.10/site-packages (from category-encoders>=2.3.0->deepchecks) (0.5.3)\nRequirement already satisfied: jupyter-client>=6.1.12 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (7.3.4)\nRequirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (1.5.6)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (5.9.0)\nRequirement already satisfied: comm>=0.1.1 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (0.1.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (0.1.6)\nRequirement already satisfied: debugpy>=1.6.5 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (1.6.7)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (23.2)\nRequirement already satisfied: pyzmq>=20 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (23.2.0)\nRequirement already satisfied: tornado>=6.1 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (6.1)\nRequirement already satisfied: traitlets>=5.4.0 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (5.7.1)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=5.3.0->deepchecks) (5.2.0)\nRequirement already satisfied: pickleshare in /databricks/python3/lib/python3.10/site-packages (from ipython>=7.15.0->deepchecks) (0.7.5)\nRequirement already satisfied: jedi>=0.16 in /databricks/python3/lib/python3.10/site-packages (from ipython>=7.15.0->deepchecks) (0.18.1)\nRequirement already satisfied: pygments>=2.4.0 in /databricks/python3/lib/python3.10/site-packages (from ipython>=7.15.0->deepchecks) (2.11.2)\nRequirement already satisfied: pexpect>4.3 in /databricks/python3/lib/python3.10/site-packages (from ipython>=7.15.0->deepchecks) (4.8.0)\nRequirement already satisfied: backcall in /databricks/python3/lib/python3.10/site-packages (from ipython>=7.15.0->deepchecks) (0.2.0)\nRequirement already satisfied: stack-data in /databricks/python3/lib/python3.10/site-packages (from ipython>=7.15.0->deepchecks) (0.2.0)\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /databricks/python3/lib/python3.10/site-packages (from ipython>=7.15.0->deepchecks) (3.0.36)\nRequirement already satisfied: decorator in /databricks/python3/lib/python3.10/site-packages (from ipython>=7.15.0->deepchecks) (5.1.1)\nRequirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8,>=7.6.5->deepchecks) (1.0.0)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8,>=7.6.5->deepchecks) (3.6.1)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8,>=7.6.5->deepchecks) (0.2.0)\nCollecting pyzmq>=20\n  Downloading pyzmq-26.0.3-cp310-cp310-manylinux_2_28_x86_64.whl (919 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 919.8/919.8 kB 60.5 MB/s eta 0:00:00\nRequirement already satisfied: nbconvert>=6.4.4 in /databricks/python3/lib/python3.10/site-packages (from jupyter-server>=2.7.2->deepchecks) (6.5.4)\nCollecting tornado>=6.1\n  Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 436.8/436.8 kB 28.1 MB/s eta 0:00:00\nRequirement already satisfied: anyio>=3.1.0 in /databricks/python3/lib/python3.10/site-packages (from jupyter-server>=2.7.2->deepchecks) (3.5.0)\nRequirement already satisfied: jinja2>=3.0.3 in /databricks/python3/lib/python3.10/site-packages (from jupyter-server>=2.7.2->deepchecks) (3.1.2)\nCollecting jupyter-client>=6.1.12\n  Downloading jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.9/105.9 kB 16.1 MB/s eta 0:00:00\nCollecting jupyter-events>=0.9.0\n  Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\nRequirement already satisfied: nbformat>=5.3.0 in /databricks/python3/lib/python3.10/site-packages (from jupyter-server>=2.7.2->deepchecks) (5.7.0)\nRequirement already satisfied: argon2-cffi>=21.1 in /databricks/python3/lib/python3.10/site-packages (from jupyter-server>=2.7.2->deepchecks) (21.3.0)\nCollecting send2trash>=1.8.2\n  Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\nCollecting websocket-client>=1.7\n  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 7.2 MB/s eta 0:00:00\nRequirement already satisfied: terminado>=0.8.3 in /databricks/python3/lib/python3.10/site-packages (from jupyter-server>=2.7.2->deepchecks) (0.17.1)\nRequirement already satisfied: prometheus-client>=0.9 in /databricks/python3/lib/python3.10/site-packages (from jupyter-server>=2.7.2->deepchecks) (0.14.1)\nCollecting jupyter-server-terminals>=0.4.4\n  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\nCollecting overrides>=5.0\n  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib>=3.3.4->deepchecks) (9.4.0)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib>=3.3.4->deepchecks) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib>=3.3.4->deepchecks) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib>=3.3.4->deepchecks) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib>=3.3.4->deepchecks) (3.0.9)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib>=3.3.4->deepchecks) (1.0.5)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib>=3.3.4->deepchecks) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<2.2.0,>=1.1.5->deepchecks) (2022.7)\nRequirement already satisfied: tenacity>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from plotly>=5.13.1->deepchecks) (8.1.0)\nCollecting python-utils\n  Downloading python_utils-3.8.2-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.22.0->deepchecks) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.22.0->deepchecks) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.22.0->deepchecks) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.22.0->deepchecks) (2.0.4)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<1.4.0,>=0.23.2->deepchecks) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<1.4.0,>=0.23.2->deepchecks) (2.2.0)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=2.7.2->deepchecks) (1.2.0)\nRequirement already satisfied: argon2-cffi-bindings in /databricks/python3/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server>=2.7.2->deepchecks) (21.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /databricks/python3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.15.0->deepchecks) (0.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2>=3.0.3->jupyter-server>=2.7.2->deepchecks) (2.1.1)\nRequirement already satisfied: platformdirs>=2.5 in /databricks/python3/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=5.3.0->deepchecks) (2.5.2)\nCollecting rfc3986-validator>=0.1.1\n  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\nCollecting jsonschema[format-nongpl]>=4.18.0\n  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.5/88.5 kB 15.0 MB/s eta 0:00:00\nCollecting rfc3339-validator\n  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\nCollecting pyyaml>=5.3\n  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 705.5/705.5 kB 27.8 MB/s eta 0:00:00\nCollecting referencing\n  Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\nCollecting python-json-logger>=2.0.4\n  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\nRequirement already satisfied: entrypoints>=0.2.2 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (0.4)\nRequirement already satisfied: lxml in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (4.9.1)\nRequirement already satisfied: pandocfilters>=1.4.1 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (1.5.0)\nRequirement already satisfied: defusedxml in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (0.7.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (0.8.4)\nRequirement already satisfied: tinycss2 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (1.2.1)\nRequirement already satisfied: jupyterlab-pygments in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (0.1.2)\nRequirement already satisfied: nbclient>=0.5.0 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (0.5.13)\nRequirement already satisfied: bleach in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (4.1.0)\nRequirement already satisfied: fastjsonschema in /databricks/python3/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server>=2.7.2->deepchecks) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /databricks/python3/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server>=2.7.2->deepchecks) (4.17.3)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.1->category-encoders>=2.3.0->deepchecks) (1.16.0)\nRequirement already satisfied: ptyprocess>=0.5 in /databricks/python3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.15.0->deepchecks) (0.7.0)\nRequirement already satisfied: wcwidth in /databricks/python3/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.15.0->deepchecks) (0.2.5)\nRequirement already satisfied: notebook>=4.4.1 in /databricks/python3/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->deepchecks) (6.5.2)\nRequirement already satisfied: pure-eval in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=7.15.0->deepchecks) (0.2.2)\nRequirement already satisfied: executing in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=7.15.0->deepchecks) (0.8.3)\nRequirement already satisfied: asttokens in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=7.15.0->deepchecks) (2.0.5)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /databricks/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.3.0->jupyter-server>=2.7.2->deepchecks) (0.18.0)\nRequirement already satisfied: attrs>=17.4.0 in /databricks/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.3.0->jupyter-server>=2.7.2->deepchecks) (22.1.0)\nCollecting rpds-py>=0.7.1\n  Downloading rpds_py-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 355.8/355.8 kB 39.2 MB/s eta 0:00:00\nCollecting jsonschema-specifications>=2023.03.6\n  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\nCollecting attrs>=17.4.0\n  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 kB 10.7 MB/s eta 0:00:00\nCollecting jsonpointer>1.13\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nCollecting webcolors>=24.6.0\n  Downloading webcolors-24.6.0-py3-none-any.whl (14 kB)\nCollecting fqdn\n  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\nCollecting isoduration\n  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\nCollecting uri-template\n  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\nRequirement already satisfied: nbclassic>=0.4.7 in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->deepchecks) (0.5.2)\nRequirement already satisfied: cffi>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=2.7.2->deepchecks) (1.15.1)\nRequirement already satisfied: webencodings in /databricks/python3/lib/python3.10/site-packages (from bleach->nbconvert>=6.4.4->jupyter-server>=2.7.2->deepchecks) (0.5.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=2.7.2->deepchecks) (2.21)\nRequirement already satisfied: notebook-shim>=0.1.0 in /databricks/python3/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->deepchecks) (0.2.2)\nCollecting arrow>=0.15.0\n  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 8.0 MB/s eta 0:00:00\nCollecting types-python-dateutil>=2.8.10\n  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\nBuilding wheels for collected packages: PyNomaly\n  Building wheel for PyNomaly (setup.py): started\n  Building wheel for PyNomaly (setup.py): finished with status 'done'\n  Created wheel for PyNomaly: filename=PyNomaly-0.3.3-py3-none-any.whl size=8480 sha256=5c3bd595f7ca4ad0f6923fa5a5ac37fc59def4c6e4c7ff0e1b604e152bac8577\n  Stored in directory: /root/.cache/pip/wheels/4c/95/c6/4cf1ec0b5c2b1b03636b35812dfbb992c04acd370b2352dc47\nSuccessfully built PyNomaly\nInstalling collected packages: websocket-client, webcolors, uri-template, types-python-dateutil, tqdm, tornado, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pyzmq, pyyaml, python-utils, python-json-logger, plotly, overrides, jsonpointer, jsonpickle, fqdn, attrs, referencing, PyNomaly, jupyter-client, arrow, jupyter-server-terminals, jsonschema-specifications, isoduration, jsonschema, category-encoders, jupyter-events, jupyter-server, deepchecks\n  Attempting uninstall: websocket-client\n    Found existing installation: websocket-client 0.58.0\n    Not uninstalling websocket-client at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'websocket-client'. No files were found to uninstall.\n  Attempting uninstall: tornado\n    Found existing installation: tornado 6.1\n    Not uninstalling tornado at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'tornado'. No files were found to uninstall.\n  Attempting uninstall: send2trash\n    Found existing installation: Send2Trash 1.8.0\n    Not uninstalling send2trash at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'Send2Trash'. No files were found to uninstall.\n  Attempting uninstall: pyzmq\n    Found existing installation: pyzmq 23.2.0\n    Not uninstalling pyzmq at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'pyzmq'. No files were found to uninstall.\n  Attempting uninstall: plotly\n    Found existing installation: plotly 5.9.0\n    Not uninstalling plotly at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'plotly'. No files were found to uninstall.\n  Attempting uninstall: attrs\n    Found existing installation: attrs 22.1.0\n    Not uninstalling attrs at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'attrs'. No files were found to uninstall.\n  Attempting uninstall: jupyter-client\n    Found existing installation: jupyter-client 7.3.4\n    Not uninstalling jupyter-client at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'jupyter-client'. No files were found to uninstall.\n  Attempting uninstall: jsonschema\n    Found existing installation: jsonschema 4.17.3\n    Not uninstalling jsonschema at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'jsonschema'. No files were found to uninstall.\n  Attempting uninstall: jupyter-server\n    Found existing installation: jupyter-server 1.23.4\n    Not uninstalling jupyter-server at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-96968a4a-f6b3-4944-b71b-12936cdbd472\n    Can't uninstall 'jupyter-server'. No files were found to uninstall.\nSuccessfully installed PyNomaly-0.3.3 arrow-1.3.0 attrs-23.2.0 category-encoders-2.6.3 deepchecks-0.18.1 fqdn-1.5.1 isoduration-20.11.0 jsonpickle-3.2.2 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 jupyter-client-8.6.2 jupyter-events-0.10.0 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 overrides-7.7.0 plotly-5.22.0 python-json-logger-2.0.7 python-utils-3.8.2 pyyaml-6.0.1 pyzmq-26.0.3 referencing-0.35.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.19.0 send2trash-1.8.3 tornado-6.4.1 tqdm-4.66.4 types-python-dateutil-2.9.0.20240316 uri-template-1.3.0 webcolors-24.6.0 websocket-client-1.8.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install deepchecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd59bdd6-68da-4577-9c47-02351573062b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = \"\"\"`age` DOUBLE,\n",
    "`workclass` STRING,\n",
    "`fnlwgt` DOUBLE,\n",
    "`education` STRING,\n",
    "`education_num` DOUBLE,\n",
    "`marital_status` STRING,\n",
    "`occupation` STRING,\n",
    "`relationship` STRING,\n",
    "`race` STRING,\n",
    "`sex` STRING,\n",
    "`capital_gain` DOUBLE,\n",
    "`capital_loss` DOUBLE,\n",
    "`hours_per_week` DOUBLE,\n",
    "`native_country` STRING,\n",
    "`income` STRING\"\"\"\n",
    "\n",
    "dataset = spark.read.csv(\"/databricks-datasets/adult/adult.data\", schema=schema)\n",
    "\n",
    "# Splitting the data to train/test set\n",
    "trainDF, testDF = dataset.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d93aeaf8-e9dd-4aed-a0cc-9254f83c807f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from deepchecks.tabular import Dataset\n",
    "\n",
    "pd_train = trainDF.toPandas()\n",
    "pd_test = testDF.toPandas()\n",
    "\n",
    "ds_train = Dataset(pd_train, label='income', cat_features=['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country'])\n",
    "ds_test = Dataset(pd_test, label='income', cat_features=['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096c68e3-26c9-4be3-8357-6cefc4f8b8e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.tabular.suites import data_integrity\n",
    "# Validate the training set\n",
    "train_res = data_integrity().run(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6f7c63e-e056-4110-af77-05ff3e541c75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Workspace/Users/tushar.pathak@tigeranalytics.com/Reports/Data_Integrity_Report.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_path = \"/Workspace/Users/tushar.pathak@tigeranalytics.com/Reports/Data_Integrity_Report.html\"\n",
    "train_res.save_as_html(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2411284-b666-4a8c-b327-b4f4048ec722",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "categoricalCols = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\"]\n",
    "\n",
    "# The following two lines are estimators. They return functions that we will later apply to transform the dataset.\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=[x + \"Index\" for x in categoricalCols])\n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"OHE\" for x in categoricalCols])\n",
    "\n",
    "# The label column (\"income\") is also a string value - it has two possible values, \"<=50K\" and \">50K\".\n",
    "# Convert it to a numeric value using StringIndexer.\n",
    "labelToIndex = StringIndexer(inputCol=\"income\", outputCol=\"label\")\n",
    "\n",
    "stringIndexerModel = stringIndexer.fit(trainDF)\n",
    "\n",
    "# This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "numericCols = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "assemblerInputs = [c + \"OHE\" for c in categoricalCols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40c6dd9e-cebd-4bd9-8e97-378d84dd71c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Define the pipeline based on the stages created in previous steps.\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder, labelToIndex, vecAssembler, lr])\n",
    "\n",
    "# Fit the pipeline model.\n",
    "pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49078d13-7a6a-490d-9acf-2d14e0ca0fd3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.ml.feature import IndexToString\n",
    "\n",
    "class PySparkModelWrapper:\n",
    "    def __init__(self, model: pyspark.ml.pipeline.PipelineModel, label_map):\n",
    "        self.model = model\n",
    "        self.idx_to_string = IndexToString(inputCol=\"prediction\", outputCol=\"predictedValue\")\n",
    "        self.idx_to_string.setLabels(label_map)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        df=spark.createDataFrame(X)\n",
    "        preds = self.idx_to_string.transform(self.model.transform(df).select('prediction')).select('predictedValue').collect()\n",
    "        return np.array(preds).reshape(-1)\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        df=spark.createDataFrame(X)\n",
    "        preds = self.model.transform(df).select('prediction').collect()\n",
    "        return np.array(preds).reshape(-1, 2)\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return np.array([1/14] * 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b64018c6-8af3-47d7-b9cc-cb475b1aeed2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Could not find model's classes, using the observed classes. In order to make sure the classes used by the model are inferred correctly, please use the model_classes argument\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Could not find model's classes, using the observed classes. In order to make sure the classes used by the model are inferred correctly, please use the model_classes argument\n"
     ]
    }
   ],
   "source": [
    "from deepchecks.tabular.suites import model_evaluation, train_test_validation\n",
    "\n",
    "eval_suite = model_evaluation()\n",
    "model_evaluation_res = eval_suite.run(ds_train,ds_test, PySparkModelWrapper(pipelineModel,\n",
    "                                      pipelineModel.stages[2].labels))\n",
    "\n",
    "train_test_suite = train_test_validation()\n",
    "train_test_res = train_test_suite.run(ds_train, ds_test, PySparkModelWrapper(pipelineModel,\n",
    "                                      pipelineModel.stages[2].labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98736b78-bf05-4583-8efa-c664aefec282",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Workspace/Users/tushar.pathak@tigeranalytics.com/Reports/Monitor_Evaluation.html'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_path = \"/Workspace/Users/tushar.pathak@tigeranalytics.com/Reports/Test_Train_Validation_Report.html\"\n",
    "train_test_res.save_as_html(report_path)\n",
    "report_path = \"/Workspace/Users/tushar.pathak@tigeranalytics.com/Reports/Monitor_Evaluation.html\"\n",
    "model_evaluation_res.save_as_html(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "693b7fe2-886d-44d2-818b-6757c574f19b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Deepchecks_Model_Testing_v1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
